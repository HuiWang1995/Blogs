# 《后端技术面试 38 讲》学习笔记 Day 09

## 25 | 数据存储架构：如何改善系统的数据存储能力？

### 原文摘抄

> 在整个互联网系统架构中，承受着最大处理压力，最难以被伸缩的，就是数据存储部分。
>
> 目前用来改善数据存储能力的主要手段包括：数据库主从复制、数据库分片和 NoSQL 数据库。
>
> 现实中，也会采用 MySQL 主主复制的方案。
>
> 使用主主复制需要注意的是，主主复制仅仅用来提升数据写操作的可用性，并不能用来提高写操作的性能。**任何时候，系统中都只能有一个数据库作为主数据库**，也就是说，所有的应用程序都必须连接到同一个主数据库进行写操作。
>
> 实践中，更常见的数据库分片算法是我们所熟悉的余数 Hash 算法，根据主键 ID 和服务器的数目进行取模计算，根据余数连接相对应的服务器。
>
> NoSQL 数据库面临的挑战之一是数据一致性问题。
>
> 对于一个分布式系统而言，网络失效一定会发生，也就是说，分区耐受性是必须要保证的，而对于互联网应用来说，可用性也是需要保证的，分布式存储系统通常需要在一致性上做一些妥协和增强。
>
> Apache Cassandra 解决数据一致性的方案是，在用户写入数据的时候，将一个数据写入集群中的三个服务器节点，等待至少两个节点响应写入成功。用户读取数据的时候，从三个节点尝试读取数据，至少等到两个节点返回数据，并根据返回数据的时间戳，选取最新版本的数据。这样，即使服务器中的数据不一致，但是最终用户还是能得到一个一致的数据，这种方案也被称为**最终一致性**。
>
> 架构是一门关于权衡的艺术，这一点在数据存储架构上表现得最为明显。

### 心得体会

1. 存储往往应为硬盘耗时更长，为了提高可靠性，不丢失数据而多份等原因，性能体现的更低。
2. 为了保持一致性，性能做出的牺牲也并不小。

### 工作体验

1. 不论是什么类型的数据库，终究会成为短板，kyligence的查询也是并发度支持并不高。几十个并发，它的查询性能就会开始抖动。

## 26 | 搜索引擎架构：如何瞬间完成海量数据检索？

### 原文摘抄

> 把这个单词、文档矩阵按照单词→文档列表的方式组织起来，就是倒排索引了
>
> Google 使用了一种叫 PageRank 的算法，计算每个网页的权重，搜索结果就按照权重排序，权重高的网页在最终结果显示的时候排在前面。

> 要相对这些站内搜索引擎的结果进行排序，就需要利用其它一些信息以及算法，比如可以利用文章获得的点赞数进行排序，点赞越多，表示越获得其它用户的认可，越应该在搜索结果中排在前面。
>
> 而这些推荐信息来自于广大参与其中的人，因此这些算法实现也被称作“集体智慧编程”。

### 心得体会

1. pageRank、集体智慧、TF(词频)等方式进行排序，也是需要根据场景来选择的。
2. 倒排索引，文章再长再多，词的数量也是有限的，不庞大的，倒排索引就高效。

### 工作体验

1. 细细想来，公共服务中心对条线采取1,2,4,8,...，512。最终查找多个条线时通过位运算进行过滤。条线的码值就是倒排索引，多条线的查询就是并集，但是它比简单的并集更快，因为可以先通过位运算生成精确条件。
